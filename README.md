
# Repo
https://github.com/mulefish/knn-vector-tutorial

# Goal
1: Show how to 'pick' random paths using a cards   
2: Show how to vectorize those paths   
3: Show how to compare those vectors   
4: Discuss why that is nice  
5: First using 'cards' and next use a slightly less simple dataset with more dimensions to show how powerful vecoriztion is   

# COPY
## An Introduction to KNN: On Comparing Apples, Oranges, and the Strange Power of Vectors
“You can’t compare apples and oranges!”—they say, as if they’ve got it all figured out. But of course, you can. In fact, that’s one of the great joys of being human: finding similarities where nobody else thought to look. Here’s the trick, though: you’ve got to think beyond your grocery list. You need to start seeing apples and oranges as more than just lunchbox filler—they’re data, my friend, they’re vectors.  
  
Imagine, if you will, that you’re standing in some cosmic fruit aisle, armed with a notepad. Every apple and orange has a story to tell—its weight, how thick its skin is, how red (or orange) it gets, and when it decides it’s ripe and ready for the world. When you jot all that down, you’re not just making a list; you’re turning that apple into a vector. Now that apple’s not just an apple anymore—it’s a point in some abstract, higher-dimensional fruit universe.  
  
And this is where things get interesting. You can toss that apple and orange into this great, multidimensional fruit salad and ask yourself: “Just how similar are they, really?” Suddenly, you find that they’re not so different after all. Maybe they’re closer cousins than you thought, or maybe they’re as distant as two fruits can be. And all you needed to figure that out was to think in terms of vectors.  
  
Now let’s introduce you to our friend K-Nearest Neighbors (KNN). KNN is like that one neighbor who’s always up in your business, poking around to see who you’re hanging out with and what you’ve been up to. It doesn’t judge—no, it just looks at all the points around you in this fruit universe, checks who your nearest neighbors are, and makes some reasonable assumptions about who you might be.  
  
You see, KNN’s not fancy; it doesn’t try to be. It’s simple, almost charmingly so. It measures the distance between data points—between vectors—and says, “Hey, if you look like an orange and all your friends are oranges, you’re probably an orange too.” And there you have it: machine learning in a nutshell. Or maybe an orange peel.  
   
So, dear reader, if you’ve ever been told you can’t compare apples to oranges, you now have my permission to roll your eyes. Because in the strange, beautiful world of machine learning, everything is comparable if you’ve got the right set of dimensions.
  
Welcome to the world of KNN and vectors. It’s a wild ride—but trust me, it’s worth it.
  

# Screenshot
![Description of the image](./screen_knn.png)

# TODO
DISCUSSION with words! Compare Apples and Oranges!
